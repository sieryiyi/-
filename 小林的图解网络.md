# 基础

### 为什么要有 TCP/IP 网络模型？

- 对于同一台设备上的进程间通信，有很多种方式，比如有管道、消息队列、共享内存、信号等方式
- 而对于不同设备上的进程间通信，就需要网络通信
- 而设备是多样性的，所以要兼容多种多样的设备，就协商出了一套通用的网络协议
- 这个网络协议是分层的，每一层都有各自的作用和职责

### TCP/UDP一些细节

- UDP 也可以实现可靠传输，把 TCP 的特性在应用层上实现就可以，不过要实现一个商用的可靠 UDP 传输协议，也不是一件简单的事情

- 应用需要传输的数据可能会非常大，因此当传输层的数据包大小超过 MSS（TCP 最大报文段长度），就要将数据包分块，这样即使中途有一个分块丢失或损坏了，只需要重新发送这一个分块，而不用重新发送整个数据包

- 端口：当设备作为接收方时，传输层则要负责把数据包传给应用，但是一台设备上可能会有很多应用在接收或者传输数据，因此需要用一个编号将应用区分开来，这个编号就是端口

### 网络层

如果 IP 报文大小超过 MTU（以太网中一般为 1500 字节）就会再次进行分片

网络号+主机号

### 网络接口层

以太网就是一种在「局域网」内，把附近的设备连接起来，使它们之间可以进行通讯的技术

### 键入网址到网页显示，期间发生了什么

- 解析 URL，生产 HTTP 请求信息

- 域名解析协议：在发送 HTTP 请求信息之前，还有一项工作需要完成，那就是查询服务器域名对应的 IP 地址，因为委托操作系统发送消息时，必须提供通信对象的 IP 地址

- 从应用层传输到传输层，由TCP或者UDP将数据打包成TCP报文的形式（三次握手），发送到网络层
  - TCP报文头部有一些状态位：例如 SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接等
  - TCP 要做流量控制，通信双方各声明一个窗口（缓存大小），标识自己当前能够的处理能力
  - TCP 协议里面会有两个端口，一个是浏览器监听的端口（通常是随机生成的），一个是 Web 服务器监听的端口（HTTP 默认端口号是 80， HTTPS 默认端口号是 443）
  - Web服务器是被动的，只有终端客户发起请求时才会响应

- 网络层将接收到的报文打包成IP数据包的形式

- 根据路由表规则，判断下一个转发目的地

- 两点传输 —— MAC，用ARP协议

  - 到了数据链路层，网络包还需要在 IP 头部的前面加上 MAC 头部



- 目前有了 MAC头部+IP头部+TCP头部+数据+帧尾部
  - 首部和尾部的一个重要作用是帧定界，也携带了一些必要的控制信息
  - 网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方
  - 因此，我们需要将数字信息转换为电信号，才能在网线上传输，也就是说，这才是真正的数据发送过程

- 发送出去的网络包会通过交换机到达下一个路由器


  - 交换机工作在 MAC 层，也称为二层网络设备，交换机的端口不具有 MAC 地址，会收下所有发送过来的包

  - 路由器是基于 IP 设计的，俗称三层网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址，路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃

  - 完成包接收操作之后，路由器就会去掉包开头的 MAC 头部，重新把下一个目的地的MAC头部加上去


- 数据包抵达服务器后，服务器会先扒开数据包的 MAC 头部，查看是否和服务器自己的 MAC 地址符合，符合就将包收起来，然后一层一层上去

- 拆开TCP 的头，里面有序列号，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃

- TCP头部里面还有端口号， HTTP 的服务器正在监听这个端口号
 
- 于是，服务器自然就知道是 HTTP 进程想要这个包，于是就将包发给 HTTP 进程

- 服务器的 HTTP 进程看到，原来这个请求是要访问一个页面，于是就把这个网页封装在 HTTP 响应报文里

- 原样传回去，然后四次挥手断开

### 各层协议（TCP/IP网络协议，四层）

- 应用层，： HTTP、DNS、FTP 等;
- 传输层：TCP/UDP
- 网络层：IP、ICMP
- 网络接口层：ARP

### Linux收发网络包

    进程通过 Socket 接口发送数据包，数据包会被网络协议栈从上到下进行逐层处理后，才会被送到网卡队列中，随后由网卡将网络包发送出去
    
    而在接收网络包时，同样也要先经过网络协议栈从下到上的逐层处理，最后才会被送到应用程序

- 网卡是计算机里的一个硬件，专门负责接收和发送网络包
- 当网卡接收到一个网络包后，会通过 DMA 技术，将网络包写入到指定的内存地址，也就是写入到 Ring Buffer ，这个是一个环形缓冲区，接着就会告诉操作系统这个网络包已经到达

网卡告知操作系统网络包到达的方法

- 最简单的一种方式就是触发中断，也就是每当网卡收到一个网络包，就触发一个中断告诉操作系统
- but，网络包很多，一直中断，CPU就不用干别的了
- 解决方法：NAPI 机制，混合「中断和轮询」（为了解决频繁中断带来的性能开销）
  - 不采用中断的方式读取数据
  - 而是首先采用中断唤醒数据接收的服务程序，然后 poll 的方法来轮询数据
    - 当有网络包到达时，会通过 DMA 技术，将网络包写入到指定的内存地址
    - 接着网卡向 CPU 发起硬件中断，当 CPU 收到硬件中断请求后，根据中断表，调用已经注册的中断处理函数（需要先「暂时屏蔽中断」，表示已经知道内存中有数据了，告诉网卡下次再收到数据包直接写内存就可以了，不要再通知 CPU 了，这样可以提高效率，避免 CPU 不停的被中断。接着，发起「软中断」，然后恢复刚才屏蔽的中断）
  - 硬件中断处理函数做的事情很少，主要耗时的工作都交给软中断处理函数了


# HTTP 篇

超文本：文字、图片、音频、视频等的混合

### 常见状态码

- 1xx：提示信息，表示还需要后续操作

- 2xx：成功
  - 204 No Content：常见的成功状态码

- 3xx：重定向，资源位置发生变动，需要客户端重新发起请求

- 4xx：客户端错误
  - 400：表示客户端请求的报文有错误，但只是个笼统的错误
  - 403：表示服务器禁止访问资源，并不是客户端的请求出错
  - 404：表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端

- 5xx：服务器错误
  - 500：与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道
  - 503：表示服务器当前很忙，暂时无法响应客户端


### HTTP 中 GET 和 POST 请求的区别

联系：是http的两种请求方式，底层都是 TCP/IP 协议，本质上都是TCP/IP连接，但由于http的标准规定和浏览器/服务器的限制，导致在应用过程中体现出一些不同

区别：
- get请求支持后退、刷新，post请求在进行后退的时候，会重新发送请求
- get一般是获取数据，一般用于搜索排序、筛选操作，post一般是提交数据，用于修改和写入数据
- get请求的数据一般会被浏览器主动缓存，post请求不会，所以如果get请求两次都请求相同数据，则第二次的消耗时间会较少

- get请求一般是放在 URL 中的，因此安全性较差，长度也受限（是因为URL的长度被浏览器和服务器限制，HTTP协议本身对 URL长度并没有做任何规定），而post请求安全性较好，长度不受限
  - 但是并不能说 GET 不如 POST 安全的，因为 HTTP 传输的内容都是明文的，虽然在浏览器地址拦看不到 POST 提交的 body 数据，但是只要抓个包就都能看到了
  - get请求只能进行url编码（URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ）
  - post请求支持多种编码


- 通常get产生一个TCP数据包，post产生两个数据包（get的效率通常要高一些，因为用get方式请求的时候，浏览器会把http的header和body一起发送出去，成功则返回200，post先发送header，成功则返回100 continue，再发送body，成功返回200）
  - post请求的过程：
    - （1）浏览器请求tcp连接（第一次握手）
    - （2）服务器答应进行tcp连接（第二次握手）
    - （3）浏览器确认，并发送post请求头（第三次握手，这个报文比较小，所以http会在此时进行第一次数据发送）
    - （4）服务器返回100 Continue响应
    - （5）浏览器发送数据
    - （6）服务器返回200 OK响应
  - get请求的过程：
    - （1）浏览器请求tcp连接（第一次握手）
    - （2）服务器答应进行tcp连接（第二次握手）
    - （3）浏览器确认，并发送get请求头和数据（第三次握手，这个报文比较小，所以http会在此时进行第一次数据发送）
    - （4）服务器返回200 OK响应
  - 目测get的总耗是post的2/3左右，这个口说无凭，网上已经有网友进行过测试
  

    
在 HTTP 协议⾥，所谓的「安全」是指请求⽅法不会「破坏」服务器上的资源。

所谓的「幂等」，意思是多次执⾏相同的操作，结果都是「相同」的。

- 那么很明显 GET ⽅法就是安全且幂等的，因为它是「只读」操作，⽆论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。

- POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多
个资源，所以不是幂等的。

### HTTP（1.1） 的特点有哪些？

特点：无状态、明文传输

- 无状态
  - 好处：服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息
  - 坏处：服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦
  - 解决方法：Cookie 技术
- 明文传输
  - 好处：在传输过程中的信息，是可方便阅读的
  - 坏处：不安全
  - 解决方法：HTTPS（数据加密）、摘要算法（防止篡改，篡改了就不能正常显示）、CA证书（验证身份）



### https具体解决方式

1、混合加密（解决窃听）：对称加密（不安全） + 非对称加密（速度慢），如果全部过程都用非对称加密，会很慢

- 在通信建立前，采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密
- 在通信过程中，全部使用对称加密的「会话秘钥」的方式加密明文数据

- 非对称加密：共有两个密钥，这两个密钥可以双向加解密的，比如可以用公钥加密内容，然后用私钥解密，也可以用私钥加密内容，公钥解密内容
  - 公钥加密，私钥解密：这个目的是为了保证内容传输的安全
  - 私钥加密，公钥解密：这个目的是为了保证消息不会被冒充，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的
    
    
    
2、摘要算法：在计算机里会用摘要算法（哈希函数）来计算出内容的哈希值，也就是内容的「指纹」，这个哈希值是唯一的，且无法通过哈希值推导出内容
    
3、数字证书

我们常说的数字签名算法，就是用的是[私钥加密，公钥解密]这种方式，不过私钥加密内容不是内容本身，而是对内容的哈希值加密

- 私钥是由服务端保管，然后服务端会向客户端颁发对应的公钥。如果客户端收到的信息，能被公钥解密，就说明该消息是由服务器发送的
  
  - 可以通过哈希算法来保证消息的完整性（摘要算法）
  - 可以通过数字签名来保证消息的来源可靠性（能确认消息是由持有私钥的一方发送的）
  - 还缺少身份验证的环节

完整步骤：
- 服务器将自己的公钥注册到CA机构
- CA机构用自己的（注意！）私钥，将服务器的公钥进行数字签名（即：加密），并颁发数字证书（包含数字签名、公钥、服务器信息等）
- 客户端拿到服务器的数字证书后，用CA的公钥（内置在浏览器或者操作系统里了）进行解密，如果解得开，说明这个证书确实是CA机构颁发的，证明里面包含的服务器公钥的可信
- 即：验证了服务器的身份，还拿到了它的公钥
- 然后拿着公钥，对数据进行加密，然后发给服务器
- 服务器拿自己的私钥解密
  
  
### SSL/TLS的工作流程

- 考虑到性能的问题，所以双方在加密应用信息时使用的是对称加密密钥
- 而对称加密密钥是不能被泄漏的，为了保证对称加密密钥的安全性，所以使用非对称加密的方式来保护对称加密密钥的协商
- 这个工作就是密钥交换算法负责的
- 最简单的 RSA 密钥交换算法
  - TLS 第一次握手（明文）：客户端生成一个随机数A，发给服务端
  - TLS 第二次握手（明文）：服务端生成一个随机数B，把B和自己的CA证书一起发回去
  - TLS 第三次握手（非对称加密）：客户端生成一个随机数C，用服务器的公钥加密后，发给服务器，服务端收到后，用 RSA 私钥解密，得到客户端发来的随机数
    -  于是，双方根据已经得到的三个随机数，生成会话密钥（Master Secret），它是对称密钥
    -  然后客户端发一个「Change Cipher Spec」，告诉服务端开始使用加密方式发送消息
    -  然后，客户端再发一个「Encrypted Handshake Message（Finishd）」消息，把之前所有发送的数据做个摘要
    -  再用会话密钥（master secret）加密一下，让服务器做个验证，验证加密通信是否可用和之前握手信息（明文）是否有被中途篡改过
  - TLS 第四次握手：服务器也是同样的操作，发「Change Cipher Spec」和「Encrypted Handshake Message」消息，如果双方都验证加密和解密没问题，那么握手正式完成

  
  
  
### http 1.0 和 http 1.1 和 http 2.0

- http 1.0：
  - 每发起一个请求，都要新建一次 TCP 连接
  - 而且是串行请求
  - 报文头信息是ascll码，数据体可以是文本或者二进制
- http 1.1：
  - 长连接：只要任意一端没有明确提出断开连接，则保持 TCP 连接状态
  - 管道网络传输：
    - 即：可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去（可以减少整体的响应时间）
    - 但是：服务器必须按照接收请求的顺序发送对这些管道化请求的响应
    - 队头堵塞：如果服务端在处理 A 请求时耗时比较长，那么后续的请求的处理都会被阻塞住
   - 以，HTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞










