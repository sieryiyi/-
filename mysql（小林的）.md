--- 整体复习---

# 索引

作用：以空间换时间，加快查找速度，类似于书本的目录，避免一页一页去查找某一页

### BST树、AVL树、B树、B+树

1、BST树：二叉排序树，即左节点 < 根 < 右节点
```
  优点：查询时间比链表快，是O(nlogn)

  缺点：如果插入的节点的值越来越大或者越来越小，则会退化为一条链表
```

2、AVL树：平衡二叉树，在BST树的基础上，其任意节点的左右子树高度差不超过1
```
  优点：不会退化为一条链表，且时间复杂度是O(nlogn)
```

3、B树：多叉树，一般称为 M阶B树，M是分叉个数
```
  --------B树特点-------------

  每个节点的值都是按照递增次序排序的，左小右大
  
  根节点的子节点个数为[2,M]，其他非叶节点的子节点个数为[ceil(M/2),M]，ceil是向上取整
  
  每个非叶节点的值（索引）个数=子节点个数-1

  --------B树优缺点-------------

  优点：B树每一个节点都包含key和value，相比于B+树，离根节点近的元素能更快被查找到

  缺点：不利于范围查找（区间查找），B树查找区间，还是得一个一个查
```

4、B+树
```
  ------------B+树特点---------------

  内部有两种节点：索引节点、叶子节点

  B+树的索引结点只用于索引，所有的数据都保存在B+树的叶子结点中；B树则是所有结点都会保存数据

  B+树的叶子结点都会被连成一条双向链表，方便区间查找

  B树的所有索引值是不会重复的，而B+树非叶子结点的索引值，最终一定会全部出现在叶子结点中

  ------------B+树优缺点---------------
  
  优点：
  
  查找区间时，可以直接通过链表进行查找
  
  中间不存储数据，因此相同大小的磁盘空间，可以容纳更多的节点元素
  
  在数据量相同的情况下，B+树的结构比B树更加“矮胖”，因此查询的IO次数也更少

  B树的查找性能并不稳定（最好情况只查询根节点，最坏情况是查找叶子节点），而B+树的每一次查找都是稳定的
```

### 磁盘读取

是上述B+树的解释

```
  和内存相比，从磁盘中读取数据的速度会慢上百倍千倍甚至万倍，所以，我们应当尽量减少从磁盘中读取数据的次数

  从磁盘中读取数据时，都是按照磁盘块来读取的，并不是一条一条的读；如果我们能把尽量多的数据放进磁盘块中，那一次磁盘读取操作就会读取更多数据，那我们查找数据的时间也会大幅度降低
  
  如果我们用树这种数据结构作为索引的数据结构，那我们每查找一次数据就需要从磁盘中读取一个节点，也就是我们说的一个磁盘块；
  
  在树的数据结构中，每个节点称为页，页就是我们上面说的磁盘块，在 MySQL 中数据读取的基本单位都是页，所以我们这里叫做页更符合 MySQL 中索引的底层数据结构
  
  B+树之所以这么做是因为在数据库中页的大小是固定的，InnoDB 中页的默认大小是 16KB。
  如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的 IO 次数又会再次减少，数据查询的效率也会更快
  
```

### MySQL的索引

默认用B+树作为索引类型：

  1、主键索引：如果有主键，用主键当索引
  
  2、如果没有主键，选一列不包含null的做索引，都没有，就自动生成一个隐藏自增id列作为索引key，这俩都属于二级索引
  
```
  PS：主键索引：叶节点存放的是实际数据，二级索引：存放的是主键值
  
  select * from product where product_no = '0002';        --这条就是拿二级索引查询
  
  过程：通过二级索引，或者叶子结点中存的主键值，再去主键索引对应的B+树中查询具体数据，即需要查两次
  
  注意：当查询的数据是能在二级索引的 B+Tree 的叶子节点里查询到，这时就不用再查主键索引查，如：
  
  select id from product where product_no = '0002';          --这条语句本身查的就是主键值，此时只需要查询一次B+树
  
  上述在二级索引的B+树中就能查询到结果的过程叫：覆盖索引
```
```
  B+Tree 存储千万级的数据只需要 3-4 层高度就可以满足，所以B+Tree 相比于 B 树和二叉树来说，最大的优势：在于查询效率很高，因为即使在数据量很大的情况，查询一个数据的磁盘 I/O 依然维持在 3-4次
```

### 索引分类

  按数据结构：B+索引，hash索引
  
  按物理存储分：主键索引、二级索引
  
  按字段特性分：主键索引、唯一索引、普通索引、前缀索引
  
  按字段个数分：单列索引、联合索引
  
### 什么时候需要索引？什么时候不需要？

  优点：提高查询速度
  
  缺点：需要占用存储空间；创建索引和维护索引要耗费时间（数据量越大耗费越大）；降低增删改的效率，因为每次表内变动，B+树为了维护自己的有序性，都要一起跟着动态维护
  
  适用场景：
```
  1、字段有唯一性的，比如商品编码

  2、经常用where查询的字段，可以提高整张表的查询速度，如果不止一个字段，可以建立联合索引

  3、经常需要group by或者order by的字段，这样在查询过程中不需要再次排序，因为B+树叶节点本身有序
```

  不适用场景：
```
  1、where / order by / group by中用不到的字段（即：列）不用创建索引

  2、数据很少的时候，不用建立索引

  3、经常更新的字段，不要建立索引
```

### 优化索引的方法

  1、前缀索引优化
```
  优点：减小索引字段的大小，进而提高索引页里面存储的值的多少，有助于提高查询效率

  缺点：排序order by不能使用前缀索引；无法把前缀索引用作覆盖索引
```

  2、覆盖索引优化
  
    从二级索引中查询得到记录，而不需要去主键索引树中再次查找，即：避免回表操作，或者覆盖索引操作
    
    方法：比如如果要查询商品的名称、价格，则可以建立联合索引：（商品ID，名称，价格）
    
    好处：不需要查询出包含整个记录的所有信息，也就减少了I/O操作
    
  3、主键索引最好是自增的
  
    （MySQL里好像只要设置为主键就默认自增？）
    
    如果是自增的，每次往页面里插入新的数据，其实就相当于添加到最后面的位置，如果页面满了，就开个新页面，类似列表的append？append的效率肯定比insert高？
    
    PS：主键的字段长度最好也小点，这样二级索引叶子节点存储的空间也就小了
    
  4、索引最好设置为 NOT NULL
  
    NULL是个无意义的值，但还是会占用物理空间
  
  5、防止索引失效

    当我们在查询条件中对索引列做了计算、函数、类型转换操作，这些情况下都会造成索引失效


# 事务

  MySQL 事务主要用于处理操作量大，复杂度高的数据： 事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行
  
  事务是一个不可分割的工作逻辑单元，在数据库系统上执行并发操作时，事务是最小的控制单元，适用于多用户同时操作的数据库系统的场景；只要有一个操作没成功，整个事务都将回滚到事务开始前

### 并发和并行

  并发：指在同一时刻只能有一条指令执行，但多个进程指令被快速的轮换执行，使得在宏观上具有多个进程同时执行的效果，但在微观上并不是同时执行的，只是把时间分成若干段，使多个进程快速交替的执行
```
    并发的程序之间有制约关系：直接制约是某个程序需要另一个程序的计算结果，间接制约是多个程序竞争某个资源
    
    并发程序在执行中是走走停停、断续推进的，任一时刻点上只有一个程序在运行
    
    1.串行是指两个或两个以上程序按顺序发生
    2.并行是指两个或以上程序在同一时间点发生
    3.并发是指两个或两个以上程序在同一时间段发生
    
    通俗一点就是你打游戏打到一半你妈妈叫你吃饭了，你打完游戏再去吃饭，这就是串行一件一件事情完成。如果你手速够快你可以放个技能吃口饭推个塔吃口饭，在游戏和吃饭之间来回切换丝毫不影响你送人头这就是并发。再如果你是大神一只手操作另一只手吃饭同时进行不耽误你carry队友这就是并行。
    
```
  并行：指在同一时刻，有多条指令在多个处理器上同时执行。所以无论从微观还是从宏观来看，二者都是一起执行的

### 并发可能存在的问题

  1、线程安全问题：在缺少合理的同步机制的情况下，多线程的执行顺序是不可预知的；为了让多线程程序的行为具有可预测性，共享变量的访问必须被合理地协调，使得一个线程对该变量的访问不会干扰到另一个线程
  
  2、活跃性问题：例如线程 A 在等待一个资源，该资源被线程 B 排他性地占有了，并且线程 B 永远不释放该资源，那么线程 A 必须永远等待下去
  
  性能风险：在多线程程序中调度器经常需要临时挂起一个线程，运行另一个线程，这被称为上下文切换；上下文切换会造成很大的开销，保存和恢复执行上下文、调度线程都需要时间，降低了多线程的性能

### 事务的运行流程举例

  比如：转账操作
  
  在转账操作前先开启事务，等所有数据库操作执行完成后，才提交事务，对于已经提交的事务来说，该事务对数据库所做的修改将永久生效，如果中途发生发生中断或错误，那么该事务期间对数据库所做的修改将会被回滚到没执行该事务之前的状态
  
### 事务特性

  1、原子性：事务要么成功，要么失败，没有中间态
  
  2、一致性：指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态，比如转账前A有100，B有100，总共200，转账后，A没钱了，B有200，总计200，不能出现总计不是200的情况
  
  3、隔离性 ☆ ：数据库允许多个并发事务同时对其数据进行读写和修改的能力，彼此之间互不影响，一个事务内部的操作对并发的其他事务是具有隔离性的
  
  4、持久性：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失
  
### 隔离性（重点）

  1、脏读：一个事务读取到了另一个事务没有提交的数据
  
  2、不可重复读：前后读取的数据不一致，即：在一个事务内多次读取同一个数据，出现前后两次读到的数据不一样的情况
  
  3、幻读：前后读取的记录数量不一致，即：在一个事务内，多次查询某个符合查询条件的「记录数量」，出现前后两次查询到的记录数量不一样的情况
  
  --------以上都会对事务的一致性产生影响----------
  
  严重性：脏读＞不可重读＞幻读
  
### 四种隔离级别

  SQL 标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能效率就越低
  
  1、读未提交：一个事务还没提交时候，它做的变更就能被其他的看到
  
  2、读提交：一个事务提交后，做的变更才能被看到（防止脏读）
  
  3、可重复读：一个事务执行过程中看到的数据，一直跟这个事务启动时候看到的一样（防止不可重复读）
  
  4、串行化：会对记录加锁，在多个事务对这条记录进行读写操作时候，后访问的事务必须等前一个事务全部完成并提交，才能继续执行（防止幻读）
  
  隔离级别：串行化＞可重复读＞读提交＞读未提交
  
  ----------串行化会使得数据库在并发事务时候，性能很差-------------
  
  MySQL的默认隔离级别：可重复读，但是它通过next-key lock 锁（行锁和间隙锁的组合）来锁住记录之间的“间隙”和记录本身，防止其他事务在这个记录之间插入新的记录，这样就避免了幻读现象
  
### 隔离级别的实现方式

  读未提交：直接读就行了

  读提交、可重复读：通过 Read View 来实现

  串行化：加锁，避免并行访问

### Read view

  MVCC：多版本 并发 控制--实现对数据库的并发访
  
  可重复读隔离级别：启动事务时生成一个 Read View（生成一个副本），然后整个事务期间都在用这个 Read View

  读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View
  
### MVCC 多版本并发控制（可重复读下）

针对 读-写冲突 可能会产生的问题而创造的

当前读：读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁

快照读：像不加锁的 select 操作就是快照读，即不加锁的非阻塞读，快照读的实现是基于多版本并发控制，即 MVCC ,可以认为 MVCC 是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销


实现原理
```
          ------通过记录的隐式字段、undo日志，READ VIEW 来实现------
  
  每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，记录的隐式字段之一roll_pointer，是个指针，指向每一个旧版本记录，可以通过它找到修改前的记录
  
  1、在读记录的时候，会先看这条记录的记录id，和当前正在进行的事务 id 中的 min_trx_id 值进行对比，如果小于，说明这条记录在事务之前就已经提交了，直接读就行
  
  2、如果在事务 B 的 Read View 的 min_trx_id 和 max_trx_id 之间，则需要判断现在这个记录的对应事务id在不在 m_ids 范围内（活跃着还未提交的其他事务），判断的结果是在的，那么说明这条记录是被还未提交的事务修改的，这时事务 B 并不会读取这个版本的记录。
  而是沿着 undo log 链条往下找旧版本的记录，直到找到 trx_id 「小于」事务 B 的 Read View 中的 min_trx_id 值的第一条记录
  
  通过这样的方式实现了，「可重复读」隔离级别下在事务期间读到的记录都是事务启动前的记录
```

### 读提交下，Read view 的工作

读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View

在可重复读隔离级别中，普通的 select 语句就是基于 MVCC 实现的快照读，也就是不会加锁的。而 select .. for update 语句就不是快照读了，而是当前读了，也就是每次读都是拿到最新版本的数据，但是它会对读到的记录加上 next-key lock 锁。
  
### 幻读解决方法（没咋看懂）

  默认隔离级别是可重复读，如果换成了串行化，则性能会很差，但是又得解决幻读：用行锁+间隙锁实现
  
  行锁（记录锁）：锁的是记录本身；
  
  间隙锁：锁的就是两个值之间的空隙，以防止其他事务在这个空隙间插入新的数据，从而避免幻读现象


# 锁

### 全局锁

```
flush tables with read lock
```
  执行后，整个数据库就处于只读状态了
  
  此时，对数据进行增删改，或者对表结构进行更改，都会阻塞
  
  释放全局锁：unlock tables
  
--------应用场景------------

  优点：用于做全数据库的逻辑备份，这样在备份期间，数据库不会进行更改
  
  缺点：备份期间，业务停滞
  
  改进：通过可重复读的隔离级别，在备份数据库前，开启这个备份事务，则整个备份事务执行期间，读到的数据记录是一样的，但此时其他事务仍然能对数据库进行更改
  
### 表级锁

（InnoDB 表级锁影响并发性能，尽量用行级锁）

1、表锁：表级别的共享锁（读锁）、表级别的独占锁（写锁）
```
  表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作

  也就是说如果本线程对学生表加了「共享表锁」，那么本线程接下来如果要对学生表执行写操作的语句，是会被阻塞的，当然其他线程对学生表进行写操作时也会被阻塞，直到锁被释放
  
  即：如果读锁，则限制了其他线程申请写锁（读锁和读锁不冲突），如果写锁，限制了其他线程申请读锁和写锁
```

2、元数据锁（MDL）

  也分读锁和写锁

  申请 MDL 锁的操作会形成一个队列，队列中写锁获取优先级高于读锁，一旦出现 MDL 写锁等待，会阻塞后续该表的所有需要加上读锁的操作

3、意向锁：在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」

```
  意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（lock tables ... read）和独占表锁（lock tables ... write）发生冲突
  
  那么有了「意向锁」，由于在对记录加独占锁前，先会加上表级别的意向独占锁，那么在加「独占表锁」时，直接查该表是否有意向独占锁，如果有就意味着表里已经有记录被加了独占锁，这样就不用去遍历表里的记录。
  
  所以，意向锁的目的是为了快速判断表里是否有记录被加锁
```


4、AOTU-INC锁

  数据库自动给某个字段赋值递增的值的时候，是通过这个锁实现的

### 行级锁

  1、记录锁：锁住某条记录

  2、间隙锁：左开右开，锁定某一个范围，不包含记录本身

  3、next-key锁：左开右闭，锁定一个范围且锁定记录本身（可重复读隔离级别就是用这个防止幻读的）
```
  行级锁加锁的单位是next-key锁：当用唯一索引进行查询时，当查询记录存在时，退化为记录锁，如果不存在，退化为间隙锁
```

### updata没加索引导致了锁全表

  在 update 语句的 where 条件没有使用索引，就会全表扫描，于是就会对所有记录加上 next-key 锁（记录锁 + 间隙锁），相当于把整个表锁住了

### 死锁

  死锁的四个必要条件：互斥、占有且等待、不可强占用、循环等待
  
  只要破坏任意一个，死锁就不会发生
  
方法：
```
  1、设置事务等待锁的超时时间：一旦超过这个时间，对这个事务进行回滚，于是锁就释放了

  2、开启主动死锁检测
```

# 日志

更新语句涉及到三个日志：

  1、回滚日志undo：实现原子性，在 Innodb 存储引擎层生成的日志
  
  2、重做日志redo：实现持久性，在 Innodb 存储引擎层生成的日志
  
  3、归档日志binlog：主要用于数据备份和主从复制， Server 层生成的日志
  
###  为什么需要 Buffer Pool？（基于内存的）

MySQL 的数据都是存在磁盘中的，那么我们要更新一条记录的时候，得先要从磁盘读取该记录，然后在内存中修改这条记录。那修改完这条记录是选择直接写回到磁盘，还是选择缓存起来呢

当然是缓存起来好，这样下次有查询语句命中了这条记录，直接读取缓存中的记录，就不需要从磁盘获取数据了

当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘

一个页的默认大小为 16KB

### 为什么需要 redo log ？

redo log 是为了防止Buffer Pool 中的脏页丢失而设计的

为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log 里面，并更新内存，这个时候更新就算完成了

在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘

### redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举？

写入 redo log 的方式使用了追加操作， 所以磁盘操作是顺序写，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是随机写。


### 为什么需要 binlog 

binlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，比如 SELECT 和 SHOW 操作

1、binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。

2、redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。


### 为什么要有 Buffer Pool？

虽然说 MySQL 的数据是存储在磁盘里的，但是也不能每次都从磁盘里面读取数据，这样性能是极差的

要想提升查询性能，加个缓存就行了嘛。所以，当数据从磁盘中取出后，缓存内存中，下次查询同样的数据的时候，直接从内存中读取。

为此，Innodb 存储引擎设计了一个缓冲池（Buffer Pool），来提高数据库的读写性能。


# 面试题

### 优化方法：主从复制

MySQL 的主从复制依赖于 binlog

复制的过程就是将 binlog 中的数据从主库传输到从库上

这个过程一般是异步的，也就是主库上执行事务操作的线程不会等待复制 binlog 的线程同步完成

在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行

### 执行一条 update 语句，期间发生了什么？

1、客户端先和SQL服务端建立连接

2、解析器：词法分析--识别出关键字 update，表名等等，语法分析--判断输入的语句是否符合 MySQL 语法

3、预处理器：判断表和字段是否存在

4、优化器：确定执行计划

5、执行器


### 两阶段提交

事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致

两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是分别是「准备（Prepare）阶段」和「提交（Commit）阶段」

事务的提交过程有两个阶段，就是将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog，具体如下

总的来说，在崩溃恢复后，只要redo log不是处于commit阶段，那么就拿着redo log中的XID去binlog中寻找，找得到就提交，否则就回滚。

在这样的机制下，两阶段提交能在崩溃恢复时，能够对提交中断的事务进行补偿，来确保redo log与binlog的数据一致性。


###  如何提高缓存命中率？ 

简单的 LRU 算法并没有被 MySQL 使用，因为简单的 LRU 算法无法避免下面这两个问题

1、预读失效:
```
  MySQL 的预读机制。
  
  程序是有空间局部性的，靠近当前被访问数据的数据，在未来很大概率会被访问到。
  
  所以，MySQL 在加载数据页时，会提前把它相邻的数据页一并加载进来，目的是为了减少磁盘 IO。但是可能这些被提前加载进来的数据页，并没有被访问，相当于这个预读是白做了，这个就是预读失效
  
  如果使用简单的 LRU 算法，就会把预读页放到 LRU 链表头部，而当 Buffer Pool空间不够的时候，还需要把末尾的页淘汰掉。
  
  如果这些预读页如果一直不会被访问到，就会出现一个很奇怪的问题，不会被访问的预读页却占用了 LRU 链表前排的位置，而末尾淘汰的页，可能是频繁访问的页，这样就大大降低了缓存命中率

```
--解决方法：最好就是让预读的页停留在 Buffer Pool 里的时间要尽可能的短，让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在 Buffer Pool 里的时间尽可能长

--解决具体操作：改进了 LRU 算法，将 LRU 划分了 2 个区域：old 区域 和 young 区域

划分这两个区域后，预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部

2、Buffer Pool 污染

当某一个 SQL 语句扫描了大量的数据时，在 Buffer Pool 空间比较有限的情况下，可能会将 Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 IO，MySQL 性能就会急剧下降，这个过程被称为 Buffer Pool 污染。

注意， Buffer Pool 污染并不只是查询语句查询出了大量的数据才出现的问题，即使查询出来的结果集很小，也会造成 Buffer Pool 污染

像前面这种全表扫描的查询，很多缓冲页其实只会被访问一次，但是它却只因为被访问了一次而进入到 young 区域，从而导致热点数据被替换了

MySQL 是这样做的，进入到 young 区域条件增加了一个停留在 old 区域的时间判断


### 索引

一张表只能有一个聚簇索引，那为了实现非主键字段的快速搜索，就引出了二级索引（非聚簇索引/辅助索引），它也是利用了 B+ 树的数据结构，但是二级索引的叶子节点存放的是主键值，不是实际数据。

因此，如果某个查询语句使用了二级索引，但是查询的数据不是主键值，这时在二级索引找到主键值后，需要去聚簇索引中获得数据行，这个过程就叫作「回表」，也就是说要查两个 B+ 树才能查到数据。不过，当查询的数据是主键值时，因为只在二级索引就能查询到，不用再去聚簇索引查，这个过程就叫作「索引覆盖」，也就是只需要查一个 B+ 树就能找到数据。

