### 内核空间、用户空间

  内核空间：这个内存空间只有内核程序可以访问
  
  用户空间：这个内存空间专门给应用程序使用
 
 
### 存储器

```
  1、CPU 中的寄存器（处理速度最快）
  
  2、CPU 缓存：L1/L2/L3 三层
  
  -------------------------以上都在CPU 内部，所以读写速度很快----------------------
  
  3、内存：如果断电会丢失
  
  4、硬盘：永久性存储，读写速度相比内存差好几个数量级
```
  我们从图书馆书架取书，把书放到桌子上，再阅读书，我们大脑就会记忆知识点，然后再经过大脑思考，这一系列过程相当于，数据从硬盘加载到内存，再从内存加载到 CPU 的寄存器和 Cache 中，然后再通过 CPU 进行处理和计算
  
# 虚拟内存

### 如何管理虚拟地址与物理地址之间的关系？

  内存分段、内存分页
  
### 内存分段

  虚拟地址：段号+段内偏移
  
  好处：产生连续内存空间
  
  存在问题：会产生内存碎片，内存交换（把占内存空间很大的程序写到磁盘上，再写回来）可以解决，但是磁盘I/O很慢
  
  
### 内存分页

  分页是把整个虚拟和物理内存空间切成⼀段段固定的大小。这样⼀个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每⼀页的大小为 4KB
  
  --页表：存储在内存中的
  
  当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行
  
  存在问题：内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费
  
  如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。一旦需要的时候，再加载进来，称为换入（Swap In）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。
  
### 段页式内存管理

1、先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制

2、接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页

这样，地址结构就由段号、段内页号和页内位移三部分组成


### 虚拟内存作用

1、可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域

2、由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题

3、页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性

### 内存分配过程

  应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存
  
  当应用程序读写了这块虚拟内存，CPU 就会去访问这个虚拟内存， 这时会发现这个虚拟内存没有映射到物理内存， CPU 就会产生缺页中断
  
  缺页中断处理函数会看是否有空闲的物理内存，如果有，就直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系
  
  如果没有空闲的物理内存，那么内核就会开始进行回收内存的工作，回收的方式主要是两种：直接内存回收和后台内存回收
  
### 内存回收

  --直接内存回收、后台内存回收
  
  直接内存回收：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行
  
  后台内存回收：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行
  
  --如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请： ——触发 OOM （Out of Memory）机制
  
  OOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置
  
### 哪些内存可以被回收

  文件页：大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了，回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存
  
  匿名页：如堆、栈等，这部分内存很可能还要再次被访问，所以不能直接释放内存，它们回收的方式是通过 Linux 的 Swap 机制，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了
  
  --都是基于LRU算法
  
  底层：维护着 active（活跃内存页链表） 和 inactive （不活跃内存页链表）两个双向链表
  
  回收内存的操作基本都会发生磁盘 I/O 的，如果回收内存的操作很频繁，意味着磁盘 I/O 次数会很多，这个过程势必会影响系统的性能，整个系统给人的感觉就是很卡
  
### 解决内存回收带来的性能影响

  1、调整参数，使得每次回收尽量先回收干净的文件页
  
  2、尽早触发后台回收
  
### 如何保护一个进程不被 OOM 杀掉

  如果你想某个进程无论如何都不能被杀掉，那你可以将 oom_score_adj 配置为 -1000
  
### 先Swap，其次还不行才会OOM

将内存数据换出磁盘，又从磁盘中恢复数据到内存的过程，就是 Swap 机制负责的




# Linux 命令

### 性能指标

TCP/IP 模型由应用层、传输层、网络层和网络接口层，共四层组成

ls -lh 文件名：命令查看日志文件的大小

cat ：用来查看文件内容的，不适用于大文件

less： less 并不会加载整个文件，而是按需加载，先是输出一小页的内容，当你要往下看的时候，才会继续加载

tail -n 数字：看日志最新部分的内容

# 调度算法

### 进程调度

1、先来先服务

2、最短作业优先

3、高响应比优先：权衡了短作业和长作业

4、CPU时间片轮转

5、最高优先级调度

6、多级反馈队列调度
```
  多个队列，优先级从高到低，分配到的CPU时间片从小到大：对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间
```

### 页面置换算法

1、先进先出置换FIFO

2、最近最久未使用LRU

3、最不常用置换算法LFU：当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰

### 磁盘调度算法

目的：提高磁盘的访问性能，一般是通过优化磁盘的访问请求顺序来做到的

原因：访问磁盘时候要寻找要访问的地方，这个过程称为"寻道"，这个过程很耗费时间

1、先来先服务

2、最短寻道时间优先：优先选择从当前磁头位置所需寻道时间最短的请求，but 可能磁头在一小块区域来回移动

3、扫描算法：磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向，这就是扫描（Scan）算法

### 最基本的 Socket 模型（基本只能一对一通信）

同步阻塞方式

给这个 Socket 绑定一个 IP 地址和端口

1、绑定端口的目的：当内核收到 TCP 报文，通过 TCP 头里面的端口号，来找到我们的应用程序，然后把数据传递给我们.

2、绑定 IP 地址的目的：一台机器是可以有多个网卡的，每个网卡都有对应的 IP 地址，当绑定一个网卡时，内核在收到该网卡上的包，才会发给我们.

### 服务器单机理论最大能连接多少个客户端？

 TCP 连接是由四元组唯一确认的，这个四元组就是：本机IP, 本机端口, 对端IP, 对端端口
 
 对于服务端 TCP 连接的四元组只有对端 IP 和端口是会变化的，所以最大 TCP 连接数 = 客户端 IP 数×客户端端口数
 
### 多进程模型

把每一个客户端和服务端的连接，分配一个进程去处理

当「子进程」退出时，实际上内核里还会保留该进程的一些信息，也是会占用内存的，如果不做好“回收”工作，就会变成僵尸进程，随着僵尸进程越多，会慢慢耗尽我们的系统资源

--存在问题：当客户端数量高达一万时，肯定扛不住的，因为每产生一个进程，必会占据一定的系统资源，而且进程间上下文切换的“包袱”是很重的，性能会大打折扣

### 多线程模型

因为一个进程下的线程的上下文切换开销比多进程小

--问题：如果每来一个连接就创建一个线程，线程运行完后，还得操作系统还得销毁线程，虽说线程切换的上写文开销不大，但是如果频繁创建和销毁线程，系统开销也是不小的

--解决方法：线程池

--问题2.0：上面基于进程或者线程模型的，其实还是有问题的。新到来一个 TCP 连接，就需要分配一个进程或者线程，那么如果要达到 C10K，意味着要一台机器维护 1 万个连接，相当于要维护 1 万个进程/线程，操作系统就算死扛也是扛不住的

### I/O 多路复用

--问题：为每个请求分配一个进程/线程的方式不合适

--解决方法：能只使用一个进程来维护多个 Socket —— I/O 多路复用技术

select/poll/epoll 这是三个多路复用接口


### select/poll

使用线性结构存储进程关心的Socket集合

### epoll

使用红黑树

# 一致性哈希

大多数网站背后肯定不是只有一台服务器提供服务，因为单机的并发量和数据量都是有限的，所以都会用多台服务器构成集群来对外提供服务

那么多个节点（后面统称服务器为节点，因为少一个字），要如何分配客户端的请求呢？

其实这个问题就是「负载均衡问题」

最基础的负载均衡算法：轮询，就是每个服务器给一个，下一次给下一个服务器，但是不能应对「分布式系统（数据分片的系统）」，因为分布式系统中，每个节点存储的数据是不同的

哈希算法：有一个很致命的问题，如果节点数量发生了变化，也就是在对系统做扩容或者缩容时，必须迁移改变了映射关系的数据，否则会出现查询不到数据的问题

-- 最坏情况下所有数据都需要迁移，所以它的数据迁移规模是 O(M)，这样数据的迁移成本太高了

-- 一致性哈希：避免分布式系统在扩容或者缩容时，发生过多的数据迁移

### 一致性哈希

一致哈希算法是对 2^32 进行取模运算，是一个固定的值

一致性哈希要进行两步哈希：
```
  第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希；
  第二步：当对数据进行存储或访问时，对数据进行哈希映射
```

所以，一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上

映射的结果值往顺时针的方向的找到第一个节点，就是存储该数据的节点

-- 存在问题：一致性哈希算法并不保证节点能够在哈希环上分布均匀，这样就会带来一个问题，会有大量的请求集中在一个节点上

### 虚拟节点

具体做法是，不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系

好处：提高负载均衡性、提高系统稳定性（当节点变化时，会有不同的节点共同分担系统的变化，因此稳定性更高）
