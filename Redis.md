# Redis --键值对（key-value）数据库

https://www.bilibili.com/video/BV1sV4y147Jz/?spm_id_from=333.788&vd_source=07999cb1d010fa9357b6650a0ee711a7

- 高可用的缓存数据库
- 执行命令由单线程负责的，不存在并发竞争的问题


### Redis 与 Memcached

  - 都是基于内存的数据库，一般用来当缓存
  - 都有过期策略
- 区别：
  - Redis 支持的数据类型更丰富（String、Hash、List、Set、ZSet），而 Memcached 只支持最简单的 key-value 数据类型
  - Redis 支持数据的持久化，Memcached 没有持久化功能，数据全部存在内存之中
  - Redis 原生支持集群模式，Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据
  - Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持

### 为什么用Redis作为MySQL的缓存

主要是因为 Redis 具备「高性能」和「高并发」两种特性

- 高性能：操作 Redis 缓存就是直接操作内存，所以速度相当快

- 高并发：单台设备的 Redis 的 QPS（Query Per Second，每秒钟处理完请求的次数） 是 MySQL 的 10 倍，Redis 单机的 QPS 能轻松破 10w，而 MySQL 单机的 QPS 很难破 1w

## 数据类型篇

### 5大数据类型

这些是 Redis 键值对中值的数据类型，这些对象的底层实现的方式叫数据结构

- String
- Hash
- List
- Set
- ZSet

后续新增数据结构：
- BitMap：二值状态统计的场景
- HyperLogLog：海量数据基数统计的场景，比如百万级网页 UV 计数等
- GEO：存储地理位置信息的场景，比如滴滴叫车
- Stream：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据

### 数据结构

- Redis 的键值对中的 key 就是字符串对象，而 value 可以是字符串对象，也可以是集合数据类型的对象，比如 List 对象、Hash 对象、Set 对象和 Zset 对象

| 字符串String | List | Hash | Set | ZSet |
| :---: | :---: |:---: | :---: | :---: |
| SDS | 双向链表 or 压缩列表（数据量少时候用）    | 哈希表 or 压缩列表 | 哈希表 or 整数集合  | 跳表 or 压缩链表|
|      | quicklist（3.2新的）   | 哈希表 or listpack（5.0新的）   |      | 跳表 or listpack|




- SDS 简单动态字符串结构（总的来说，Redis 的 SDS 结构在原本字符数组之上，增加了三个元数据）
  - len：记录长度，省去遍历数组找长度的时间，且使得二进制安全
  - alloc：表示分配给数组的空间大小，如果不够，会自动扩展，所以不会出现缓冲区溢出
  - flags：用来表示不同类型的 SDS，为了能灵活保存不同大小的字符串，从而有效节省内存空间，比如，在保存小字符串时，结构头占用空间也比较少
  
  用来解决 C 语言字符串的缺陷

- 双向链表
  - 提供了链表头指针 head、链表尾节点 tail、链表节点数量 len
  - 链表节点可以保存各种不同类型的值
  - 缺点：链表每个节点之间的内存都是不连续的，意味着无法很好利用 CPU 缓存，能很好利用 CPU 缓存的数据结构就是数组，因为数组的内存是连续的，这样就可以充分利用 CPU 缓存来加速访问
  - 因为要存前后指针，开销比较大

- 压缩列表
  -  Redis 为了节约内存而开发的
  -  由连续内存块组成的顺序型数据结构
  -  查找复杂度高
  -  存在连锁更新问题：在特殊情况下产生的连续多次空间扩展操作

- 哈希表
  - Redis 采用了「链式哈希」来解决哈希冲突
  - 随着链表长度的增加，查询时间增加 → rehash
  - 在实际使用哈希表时，Redis 定义一个 dict 结构体，这个结构体里定义了两个哈希表，第二个一般分配空间是第一个的两倍，rehash的时候就要用到这个
  - but 迁移数据很废资源
  - 渐进式rehash：每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上
  - 负载因子≥1 时候rehash

- 整数集合
  - 好处是节省内存资源
  - 如果一直向整数集合添加 int16_t 类型的元素，那么整数集合的底层实现就一直是用 int16_t 类型的数组（节省内存）
  - 只有在我们要将 int32_t 类型或 int64_t 类型的元素添加到集合时，才会对数组进行升级操作
  - 如果真的内存巨多不怕浪费，直接用int64_t 类型的数组存最方便了

- 跳表
  - 一种「多层」的有序链表
  - 能快读定位数据

- quicklist

  - 其实 quicklist 就是「双向链表 + 压缩列表」组合，因为一个 quicklist 就是一个链表，而链表中的每个元素又是一个压缩列表
  - 压缩列表的不足：虽然压缩列表是通过紧凑型的内存布局节省了内存开销，但是因为它的结构设计，如果保存的元素数量增加，或者元素变大了，压缩列表会有「连锁更新」的风险，一旦发生，会造成性能下降
  - 控制每个链表节点中的压缩列表的大小，规避连锁更新的问题
  - 在向 quicklist 添加一个元素的时候，不会像普通的链表那样，直接新建一个链表节点。而是会检查插入位置的压缩列表是否能容纳该元素，如果能容纳就直接保存到 quicklistNode 结构里的压缩列表，如果不能容纳，才会新建一个新的 quicklistNode 结构

- listpack
  - quicklist 并没有完全解决连锁更新的问题
  - listpack 中每个节点不再包含前一个节点的长度
  - 还是用一块连续的内存空间来紧凑地保存数据（之前压缩列表的优点保存了下来）
  - 并且为了节省内存的开销，listpack 节点会采用不同的编码方式保存不同大小的数据




### 为什么用跳表而不用平衡树（AVL树、红黑树等等）

- 跳表更容易实现
- 更容易范围查找
- 增加元素时候，跳表因为本质还是链表，增加起来要简单，而红黑树需要删除等操作

### Redis 是单线程吗？

- Redis 单线程指的是「接收客户端请求->解析请求 ->进行数据读写等操作->发送数据给客户端」这个过程是由一个线程（主线程）来完成的，这也是我们常说 Redis 是单线程的原因
- 即：单线程指的是网络请求模块使用了一个线程（所以不需考虑并发安全性），即一个线程处理所有网络请求，其他模块仍用了多个线程
- 多线程在面对I/O频繁的任务时候效果很好，但如果是CPU密集型的任务，就不用总切换了

### Redis 高并发的原因

- 大部分操作都在内存中完成，并且采用了高效的数据结构
- 采用单线程模型可以避免了多线程之间的竞争
- 采用了 I/O 多路复用机制处理大量的客户端 Socket 请求
  - IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制


### select/poll/epoll 

这是三个多路复用接口

- select
  - 将已连接的 Socket 都放到一个文件描述符集合
  - 然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生
  - 遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写
  - 再把整个文件描述符集合拷贝回用户态里
  - 然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理
  - 使用固定长度的 BitsMap 表示文件描述符集合
  - 所支持的文件描述符的个数是有限制的
  
- poll
  - 用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制
  - 和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合
  - 因此都需要遍历文件描述符集合来找到可读或可写的 Socket
  - 而且也需要在用户态与内核态之间拷贝文件描述符集合

- epoll
  - epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字，注意！！在内核里
  - select/poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配
  - 内核里维护了一个链表来记录就绪事件，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数
  - 不需要像 select/poll 那样轮询扫描整个 socket 集合

### Socket 编程

| 最基础的socket 编程 | 多进程模型 |  多线程模型  | I/O的多路复用|
|:---:|:---:|:---:|:---:|
| 基本只能一对一通信 | 每来一个客户端连接，就分配一个进程 | 来一个，就分配一个线程| 可以只在一个进程里处理多个文件的 I/O|
|阻塞I/O模型|   上下文切换开销太大了 |上下文切换开销小一点了||


## 持久化篇

### RDB

周期性备份是分钟级别的

- Redis 的快照是全量快照，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中
- 所以执行快照是一个比较重的操作
- 如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多





### AOF持久化

  - 把所有写入命令都写入到AOF文件（硬盘里），以保证死机后也不丢失
  
  - 把要写入的命令
    - 先写入到临时缓冲区aof_buf
    - 通过write()系统调用，将缓冲区的数据写入到AOF文件，此时AOF文件在内核缓冲区 page cache
    - 等待内核将数据写入磁盘
  
  - 随着AOF文件越来越大，需要进行压缩：AOF重写，只写入最终数据状态
    - 在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」
    - 等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件
  
  - 用一个子进程去专门进行重写操作
    -  子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程
  
  - 再用一个缓冲区：aof重写缓冲区，在重写的过程中，记录来的新的命令，等重写完成，再把这些命令也写入AOF文件


### 能不能有了AOF后不要RDB？

不能

- AOF 日志记录的是操作命令，不是实际的数据
  - 用 AOF 方法做故障恢复时，需要全量把日志都执行一遍
  - 一旦 AOF 日志非常多，势必会造成 Redis 的恢复操作缓慢

- RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据
- 因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些

最好是混合使用

- AOF生成快、恢复慢，数据丢失少
- RDB相反，数据恢复很快，但是快照的频率不好把握
- 混合操作
  - 在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件
  - 重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件

- 重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样加载的时候速度会很快
- 加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得数据更少的丢失
  
  
  
## 高可用篇

### Redis 哨兵

  - 负责调度主节点、从节点

  - 如果主节点掉线，调度某一个从节点充当主节点

  - 为了及时获得和更新主从节点信息，每隔10秒用info命令向主节点询问都有哪些从节点

  - 每隔10s用ping询问子节点是否掉线（多个哨兵共同确定掉线，才是掉线）

  - 如果主节点掉线，启动故障转移

  - 先选一个新的主节点 → 让其他子节点从新的主节点中同步数据 → 将掉线的主节点改为从节点

  - 选新的主节点的思路：优先级越高的；复制偏移量越大的；断开主节点时间越短的

### 缓存击穿、缓存穿透、缓存雪崩
