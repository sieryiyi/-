# Redis --键值对（key-value）数据库

https://www.bilibili.com/video/BV1sV4y147Jz/?spm_id_from=333.788&vd_source=07999cb1d010fa9357b6650a0ee711a7

- 高可用的缓存数据库
- 执行命令由单线程负责的，不存在并发竞争的问题


### Redis 与 Memcached

  - 都是基于内存的数据库，一般用来当缓存
  - 都有过期策略
- 区别：
  - Redis 支持的数据类型更丰富（String、Hash、List、Set、ZSet），而 Memcached 只支持最简单的 key-value 数据类型
  - Redis 支持数据的持久化，Memcached 没有持久化功能，数据全部存在内存之中
  - Redis 原生支持集群模式，Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据
  - Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持

### 为什么用Redis作为MySQL的缓存

主要是因为 Redis 具备「高性能」和「高并发」两种特性

- 高性能：操作 Redis 缓存就是直接操作内存，所以速度相当快

- 高并发：单台设备的 Redis 的 QPS（Query Per Second，每秒钟处理完请求的次数） 是 MySQL 的 10 倍，Redis 单机的 QPS 能轻松破 10w，而 MySQL 单机的 QPS 很难破 1w

## 数据类型篇

### 5大数据类型

这些是 Redis 键值对中值的数据类型，这些对象的底层实现的方式叫数据结构

- String
- Hash
- List
- Set
- ZSet

后续新增数据结构：
- BitMap：二值状态统计的场景
- HyperLogLog：海量数据基数统计的场景，比如百万级网页 UV 计数等
- GEO：存储地理位置信息的场景，比如滴滴叫车
- Stream：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据

### 数据结构

- Redis 的键值对中的 key 就是字符串对象，而 value 可以是字符串对象，也可以是集合数据类型的对象，比如 List 对象、Hash 对象、Set 对象和 Zset 对象

| 字符串String | List | Hash | Set | ZSet |
| :---: | :---: |:---: | :---: | :---: |
| SDS | 双向链表 or 压缩列表（数据量少时候用）    | 哈希表 or 压缩列表 | 哈希表 or 整数集合  | 跳表 or 压缩链表|
|      | quicklist（3.2新的）   | 哈希表 or listpack（5.0新的）   |      | 跳表 or listpack|




- SDS 简单动态字符串结构（总的来说，Redis 的 SDS 结构在原本字符数组之上，增加了三个元数据）
  - len：记录长度，省去遍历数组找长度的时间，且使得二进制安全
  - alloc：表示分配给数组的空间大小，如果不够，会自动扩展，所以不会出现缓冲区溢出
  - flags：用来表示不同类型的 SDS，为了能灵活保存不同大小的字符串，从而有效节省内存空间，比如，在保存小字符串时，结构头占用空间也比较少
  
  用来解决 C 语言字符串的缺陷

- 双向链表
  - 提供了链表头指针 head、链表尾节点 tail、链表节点数量 len
  - 链表节点可以保存各种不同类型的值
  - 缺点：链表每个节点之间的内存都是不连续的，意味着无法很好利用 CPU 缓存，能很好利用 CPU 缓存的数据结构就是数组，因为数组的内存是连续的，这样就可以充分利用 CPU 缓存来加速访问
  - 因为要存前后指针，开销比较大

- 压缩列表
  -  Redis 为了节约内存而开发的
  -  由连续内存块组成的顺序型数据结构
  -  查找复杂度高
  -  存在连锁更新问题：在特殊情况下产生的连续多次空间扩展操作

- 哈希表
  - Redis 采用了「链式哈希」来解决哈希冲突
  - 随着链表长度的增加，查询时间增加 → rehash
  - 在实际使用哈希表时，Redis 定义一个 dict 结构体，这个结构体里定义了两个哈希表，第二个一般分配空间是第一个的两倍，rehash的时候就要用到这个
  - but 迁移数据很废资源
  - 渐进式rehash：每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上
  - 负载因子≥1 时候rehash

- 整数集合
  - 好处是节省内存资源
  - 如果一直向整数集合添加 int16_t 类型的元素，那么整数集合的底层实现就一直是用 int16_t 类型的数组（节省内存）
  - 只有在我们要将 int32_t 类型或 int64_t 类型的元素添加到集合时，才会对数组进行升级操作
  - 如果真的内存巨多不怕浪费，直接用int64_t 类型的数组存最方便了

- 跳表
  - 一种「多层」的有序链表
  - 能快读定位数据

- quicklist

  - 其实 quicklist 就是「双向链表 + 压缩列表」组合，因为一个 quicklist 就是一个链表，而链表中的每个元素又是一个压缩列表
  - 压缩列表的不足：虽然压缩列表是通过紧凑型的内存布局节省了内存开销，但是因为它的结构设计，如果保存的元素数量增加，或者元素变大了，压缩列表会有「连锁更新」的风险，一旦发生，会造成性能下降
  - 控制每个链表节点中的压缩列表的大小，规避连锁更新的问题
  - 在向 quicklist 添加一个元素的时候，不会像普通的链表那样，直接新建一个链表节点。而是会检查插入位置的压缩列表是否能容纳该元素，如果能容纳就直接保存到 quicklistNode 结构里的压缩列表，如果不能容纳，才会新建一个新的 quicklistNode 结构

- listpack
  - quicklist 并没有完全解决连锁更新的问题
  - listpack 中每个节点不再包含前一个节点的长度
  - 还是用一块连续的内存空间来紧凑地保存数据（之前压缩列表的优点保存了下来）
  - 并且为了节省内存的开销，listpack 节点会采用不同的编码方式保存不同大小的数据




### 为什么用跳表而不用平衡树（AVL树、红黑树等等）

- 跳表更容易实现
- 更容易范围查找
- 增加元素时候，跳表因为本质还是链表，增加起来要简单，而红黑树需要删除等操作

### Redis 是单线程吗？

- Redis 单线程指的是「接收客户端请求->解析请求 ->进行数据读写等操作->发送数据给客户端」这个过程是由一个线程（主线程）来完成的，这也是我们常说 Redis 是单线程的原因
- 即：单线程指的是网络请求模块使用了一个线程（所以不需考虑并发安全性），即一个线程处理所有网络请求，其他模块仍用了多个线程
- 多线程在面对I/O频繁的任务时候效果很好，但如果是CPU密集型的任务，就不用总切换了

### Redis 高并发的原因

- 大部分操作都在内存中完成，并且采用了高效的数据结构
- 采用单线程模型可以避免了多线程之间的竞争
- 采用了 I/O 多路复用机制处理大量的客户端 Socket 请求
  - IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制


### select/poll/epoll 

这是三个多路复用接口

- select
  - 将已连接的 Socket 都放到一个文件描述符集合
  - 然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生
  - 遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写
  - 再把整个文件描述符集合拷贝回用户态里
  - 然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理
  - 使用固定长度的 BitsMap 表示文件描述符集合
  - 所支持的文件描述符的个数是有限制的
  
- poll
  - 用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制
  - 和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合
  - 因此都需要遍历文件描述符集合来找到可读或可写的 Socket
  - 而且也需要在用户态与内核态之间拷贝文件描述符集合

- epoll
  - epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字，注意！！在内核里
  - select/poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配
  - 内核里维护了一个链表来记录就绪事件，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数
  - 不需要像 select/poll 那样轮询扫描整个 socket 集合

### Socket 编程

| 最基础的socket 编程 | 多进程模型 |  多线程模型  | I/O的多路复用|
|:---:|:---:|:---:|:---:|
| 基本只能一对一通信 | 每来一个客户端连接，就分配一个进程 | 来一个，就分配一个线程| 可以只在一个进程里处理多个文件的 I/O|
|阻塞I/O模型|   上下文切换开销太大了 |上下文切换开销小一点了||


## 持久化篇

### RDB

周期性备份是分钟级别的

- Redis 的快照是全量快照，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中
- 所以执行快照是一个比较重的操作
- 如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多





### AOF持久化

  - 把所有写入命令都写入到AOF文件（硬盘里），以保证死机后也不丢失
  
  - 把要写入的命令
    - 先写入到临时缓冲区aof_buf
    - 通过write()系统调用，将缓冲区的数据写入到AOF文件，此时AOF文件在内核缓冲区 page cache
    - 等待内核将数据写入磁盘
  
  - 随着AOF文件越来越大，需要进行压缩：AOF重写，只写入最终数据状态
    - 在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」
    - 等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件
  
  - 用一个子进程去专门进行重写操作
    -  子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程
  
  - 再用一个缓冲区：aof重写缓冲区，在重写的过程中，记录来的新的命令，等重写完成，再把这些命令也写入AOF文件


### 能不能有了AOF后不要RDB？

不能

- AOF 日志记录的是操作命令，不是实际的数据
  - 用 AOF 方法做故障恢复时，需要全量把日志都执行一遍
  - 一旦 AOF 日志非常多，势必会造成 Redis 的恢复操作缓慢

- RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据
- 因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些

最好是混合使用

- AOF生成快、恢复慢，数据丢失少
- RDB相反，数据恢复很快，但是快照的频率不好把握
- 混合操作
  - 在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件
  - 重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件

- 重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样加载的时候速度会很快
- 加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得数据更少的丢失
  
## 过期删除 + 内存淘汰

### 过期删除

- Redis 可以对 key 设置过期时间，因此需要有相应的机制将已过期的键值对删除
- 当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中
  - 如果不在，则正常读取键值（比如不设置过期的热点数据？）
  - 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期


过期删除策略
- 定时删除
  - 对内存最友好
  - but，在过期 key 比较多的情况下，删除过期 key 可能会占用相当一部分 CPU 时间
- 惰性删除：来一个查询，发现过期了，才删除
- 定期删除
  - 每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key

Redis 选择「惰性删除+定期删除」这两种策略配和使用

### 内存淘汰

当 Redis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用内存淘汰策略删除符合条件的 key

- 不进行数据淘汰的策略
  - 当运行内存超过最大设置内存时，不淘汰任何数据，而是不再提供服务，直接返回错误
- 进行数据淘汰的策略
  - 在设置了过期时间的数据中进行淘汰
    - 随机淘汰
    - 优先淘汰更早过期的key
    - 近似LRU：淘汰最久没有被使用的
    - LFU：淘汰最少使用的
  - 在所有数据范围内进行淘汰
    - 随机淘汰
    - LRU
    - LFU

Redis 的 LRU 是一种近似 LRU 算法
  - LRU需要额外的空间保存一个链表
  - 维护链表中某个节点移到开头很废资源
  - 实现方式：在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间
  - 存在问题：缓存污染
    - 应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间
 
 LFU
 - 会记录每个数据的访问次数
 - 根据访问频率进行淘汰（访问次数/时间）




  
## 高可用篇

### 主从复制、读写分离

- 主服务器可以进行读写操作
  - 当发生写操作时，自动将写操作同步给从服务器（从而保证数据一致）
  - 从服务器一般是只读，并接受主服务器同步过来写操作命令
- 主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接（长连接）

当数据过多、主服务器压力过大时候，可以再设置一级从服务器
  - 从服务器可以有自己的从服务器
    - 可以接收主服务器的同步数据
    - 自己也可以同时作为主服务器的形式将数据同步给从服务器

主从复制共有三种方式
| 全量复制 | 增量复制|  基于长连接的命令传播 |
|:---:|:---:|:---:|
| 一个长连接挂了重连后，把所有数据复制给子服务器 | 只复制断线期间没有同步的数据（有一定方法去判断哪些没同步） | 正常连接时候的数据同步方式 |



### Redis 哨兵

  - 负责调度主节点、从节点

  - 如果主节点掉线，调度某一个从节点充当主节点

  - 为了及时获得和更新主从节点信息，每隔10秒用info命令向主节点询问都有哪些从节点

  - 每隔10s用ping询问子节点是否掉线（多个哨兵共同确定掉线，才是掉线）

  - 如果主节点掉线，启动故障转移

    - 先在原来主节点的子节点里选一个新的主节点
    - 让其他子节点从新的主节点中同步数据
    - 将掉线的主节点改为从节点
    - 通知客户端

  - 选新的主节点的思路
    - 优先级越高的
    - 复制偏移量越大的
    - 断开主节点时间越短的

### 缓存击穿、缓存穿透、缓存雪崩

- 缓存击穿
  - 某个热点数据过期了，如果此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库
  - 那么数据库很容易就被高并发的请求冲垮
    - 使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在（即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运）
    - 缓存空值或者默认值（即：返回一个值，避免客户端一直问一直问）
    - 限制非法请求（因为缓存穿透很可能是黑客恶意攻击）
  
- 缓存穿透
  - 当用户访问的数据，既不在缓存中，也不在数据库中
  - 那么也就没法建立这个的缓存
  - 下次再来这个请求，还是得重新再找一遍（缓存找一遍，数据库找一遍）
  - 那么当有大量这样的请求到来时，数据库的压力骤增
  - 方法：互斥锁、不给热点设置过期时间
    - 由后台异步更新缓存
    - 或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间

- 缓存雪崩
  - 大量热点数据过期
  - 或者Redis挂了

|大量数据过期|Redis挂了|
|:---:|:---:|
|均匀设置过期时间  （给这些数据的过期时间加上一个随机数）|   启动服务熔断机制，暂停业务应用对缓存服务的访问，直接返回错误|
|互斥锁：当业务线程在处理用户请求时，如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存，当缓存构建完成后，再释放锁| 启用请求限流机制，只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务|
|双key策略：对缓存数据可以使用两个 key，一个是主 key，会设置过期时间，一个是备 key，不会设置过期|构建 Redis 缓存高可靠集群 |
|后台更新缓存：业务线程不再负责更新缓存，缓存也不设置有效期，而是让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新| |

### 数据库（MySQL）和缓存（Redis）如何保证一致性？

- 旁路缓存策略
  - 在更新数据时，不更新缓存，而是更新数据库，并删除缓存中的数据
    - 先更新数据库，再删除缓存
    - 在实际中，缓存的写入通常要远远快于数据库的写入
    - 兜底的方案，给缓存加上了过期时间
  - 到读取数据时，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中

- 存在问题：如果第二步删除缓存失败，依然会出现不一致问题
  - 重试机制：引入消息队列
    - 将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据
    - 删除失败就重试，重试好多次还是失败就报错
    - 删除成功就从消息队列里移出去

### 回滚

Redis没有提供回滚机制，即不一定能保证原子性

1

2

3

4




### 分布式锁

- 分布式锁：是用于分布式环境下并发控制的一种机制
- 用于控制某个资源在同一时刻只能被一个应用所使用

### redis分布式锁的理解，如何实现？

- Redis 本身可以被多个客户端共享访问
- 正好就是一个共享存储系统
- 可以用来保存分布式锁（？）
- 而且 Redis 的读写性能高（因为在内存里），可以应对高并发的锁操作场景（高并发情况下，需要频繁加锁解锁，而锁保存在Redis里，读取很快？）

实现方式：
- Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁
- （SET lock_key unique_value NX PX 10000） 
- 如果 key 不存在，则显示插入成功，可以用来表示加锁成功
- 如果 key 存在，则会显示插入失败，可以用来表示加锁失败（key来表示锁？）

基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件：

- 加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁
- 锁变量需要设置过期时间，加上 EX/PX 选项，设置其过期时间
- 锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端

而解锁的过程就是将 lock_key 键删除（del lock_key）


### 如果redis作为分布式锁的时候，主节点挂掉了，但是数据还没有同步到从节点，这种情况怎么办？

Redis 主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性

解决方法：红锁
- 为了保证集群环境下分布式锁的可靠性，Redis 官方已经设计了一个分布式锁算法 Redlock（红锁）
- 它是基于多个 Redis 节点的分布式锁
- 即使有节点发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作
- 官方推荐是至少部署 5 个 Redis 节点，而且都是主节点！！！它们之间没有任何关系，都是一个个孤立的节点

思路：
- 让客户端和多个独立的 Redis 主节点依次请求申请加锁
- 如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败
- 这样一来，即使有某个 Redis 节点发生故障，因为锁的数据在其他主节点上也有保存（且主从复制到了它们分别的子节点上），所以客户端仍然可以正常地进行锁操作，锁的数据也不会丢失
